{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shuvangiadhikari/ANAISLabExercises/blob/main/generativeAI_pubmed_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E9wgw-lB3G75"
      },
      "source": [
        "PubMed is a free resource supporting the search and retrieval of biomedical and life sciences literature with the aim of improving health–both globally and personally.\n",
        "The PubMed database contains more than 35 million citations and abstracts of biomedical literature. It does not include full text journal articles; however, links to the full text are often present when available from other sources, such as the publisher's website or PubMed Central (PMC).\n",
        "Available to the public online since 1996, PubMed was developed and is maintained by the National Center for Biotechnology Information (NCBI), at the U.S. National Library of Medicine (NLM), located at the National Institutes of Health (NIH)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MSFhLiTX3iR1"
      },
      "source": [
        "\n",
        "\n",
        "*   Install pubmed python API packge\n",
        "*   Get abstracts\n",
        "*   Clean texts\n",
        "*   Save data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4OvEexbCy3Tg"
      },
      "source": [
        "Intall package if it has not been installed before"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Itq5EjGxDbcv",
        "outputId": "c2bc1438-cd85-41a8-fa8a-86afd921e922"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting metapub\n",
            "  Downloading metapub-0.5.5.tar.gz (120 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m120.3/120.3 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from metapub) (67.7.2)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from metapub) (4.9.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from metapub) (2.27.1)\n",
            "Collecting eutils (from metapub)\n",
            "  Downloading eutils-0.6.0-py2.py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.9/41.9 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting habanero (from metapub)\n",
            "  Downloading habanero-1.2.3-py2.py3-none-any.whl (30 kB)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from metapub) (0.8.10)\n",
            "Collecting cssselect (from metapub)\n",
            "  Downloading cssselect-1.2.0-py2.py3-none-any.whl (18 kB)\n",
            "Collecting unidecode (from metapub)\n",
            "  Downloading Unidecode-1.3.6-py3-none-any.whl (235 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.9/235.9 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docopt (from metapub)\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from metapub) (1.16.0)\n",
            "Collecting tox (from metapub)\n",
            "  Downloading tox-4.6.3-py3-none-any.whl (152 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.2/152.2 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pytest in /usr/local/lib/python3.10/dist-packages (from metapub) (7.2.2)\n",
            "Collecting coloredlogs (from metapub)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-Levenshtein (from metapub)\n",
            "  Downloading python_Levenshtein-0.21.1-py3-none-any.whl (9.4 kB)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->metapub)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pytz in /usr/local/lib/python3.10/dist-packages (from eutils->metapub) (2022.7.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from habanero->metapub) (4.65.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->metapub) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->metapub) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->metapub) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->metapub) (3.4)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.10/dist-packages (from pytest->metapub) (23.1.0)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.10/dist-packages (from pytest->metapub) (2.0.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from pytest->metapub) (23.1)\n",
            "Requirement already satisfied: pluggy<2.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from pytest->metapub) (1.2.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /usr/local/lib/python3.10/dist-packages (from pytest->metapub) (1.1.1)\n",
            "Requirement already satisfied: tomli>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pytest->metapub) (2.0.1)\n",
            "Collecting Levenshtein==0.21.1 (from python-Levenshtein->metapub)\n",
            "  Downloading Levenshtein-0.21.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (172 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m172.5/172.5 kB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rapidfuzz<4.0.0,>=2.3.0 (from Levenshtein==0.21.1->python-Levenshtein->metapub)\n",
            "  Downloading rapidfuzz-3.1.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m64.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cachetools>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from tox->metapub) (5.3.1)\n",
            "Collecting chardet>=5.1 (from tox->metapub)\n",
            "  Downloading chardet-5.1.0-py3-none-any.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.1/199.1 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting colorama>=0.4.6 (from tox->metapub)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: filelock>=3.12.2 in /usr/local/lib/python3.10/dist-packages (from tox->metapub) (3.12.2)\n",
            "Requirement already satisfied: platformdirs>=3.5.3 in /usr/local/lib/python3.10/dist-packages (from tox->metapub) (3.7.0)\n",
            "Collecting pyproject-api>=1.5.2 (from tox->metapub)\n",
            "  Downloading pyproject_api-1.5.2-py3-none-any.whl (12 kB)\n",
            "Collecting virtualenv>=20.23.1 (from tox->metapub)\n",
            "  Downloading virtualenv-20.23.1-py3-none-any.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m90.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting distlib<1,>=0.3.6 (from virtualenv>=20.23.1->tox->metapub)\n",
            "  Downloading distlib-0.3.6-py2.py3-none-any.whl (468 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.5/468.5 kB\u001b[0m \u001b[31m53.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: metapub, docopt\n",
            "  Building wheel for metapub (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for metapub: filename=metapub-0.5.5-py3-none-any.whl size=135353 sha256=27e143cd8f97f3fd774c9e82486a6a43f0ababcc2b21f3dbfe55de198b1132e0\n",
            "  Stored in directory: /root/.cache/pip/wheels/14/2f/e7/b1df60d116db48f981dc3a8b320c9ba2d27d2526d5bad3579d\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13707 sha256=fdd4708336e9361552a0387862ce5c8fc8a4e4cc4d6cd531944e48f860ea2a23\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/ab/d4/5da2067ac95b36618c629a5f93f809425700506f72c9732fac\n",
            "Successfully built metapub docopt\n",
            "Installing collected packages: docopt, distlib, virtualenv, unidecode, rapidfuzz, pyproject-api, humanfriendly, cssselect, colorama, chardet, tox, Levenshtein, habanero, eutils, coloredlogs, python-Levenshtein, metapub\n",
            "  Attempting uninstall: chardet\n",
            "    Found existing installation: chardet 4.0.0\n",
            "    Uninstalling chardet-4.0.0:\n",
            "      Successfully uninstalled chardet-4.0.0\n",
            "Successfully installed Levenshtein-0.21.1 chardet-5.1.0 colorama-0.4.6 coloredlogs-15.0.1 cssselect-1.2.0 distlib-0.3.6 docopt-0.6.2 eutils-0.6.0 habanero-1.2.3 humanfriendly-10.0 metapub-0.5.5 pyproject-api-1.5.2 python-Levenshtein-0.21.1 rapidfuzz-3.1.1 tox-4.6.3 unidecode-1.3.6 virtualenv-20.23.1\n"
          ]
        }
      ],
      "source": [
        " pip install metapub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OM4h28wGDktz",
        "outputId": "9620540a-23dd-46be-938c-79543eacfa10"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at gdrive\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive\n",
        "drive.mount('gdrive')\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H3-T6qf5D_Kq"
      },
      "outputs": [],
      "source": [
        "data_dir = \"/content/gdrive/My Drive/GenerativeAI/\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4BsOOGysEqIT"
      },
      "outputs": [],
      "source": [
        "#Extract the abstract using the keywords\n",
        "\n",
        "\n",
        "def get_pubmed_abs(keywords, num_article):\n",
        "  from metapub import PubMedFetcher\n",
        "  fetch = PubMedFetcher()\n",
        "  pmids = fetch.pmids_for_query(keywords, retmax=num_article)\n",
        "  abstracts = {}\n",
        "  for pmid in pmids:\n",
        "    abstracts[pmid] = fetch.article_by_pmid(pmid).abstract\n",
        "  Abstract = pd.DataFrame(list(abstracts.items()),columns = ['pmid','Abstract'])\n",
        "  return Abstract\n",
        "\n",
        "def get_pubmed_title(keywords, num_article):\n",
        "  from metapub import PubMedFetcher\n",
        "  fetch = PubMedFetcher()\n",
        "  pmids = fetch.pmids_for_query(keywords, retmax=num_article)\n",
        "  abstracts = {}\n",
        "  for pmid in pmids:\n",
        "    abstracts[pmid] = fetch.article_by_pmid(pmid).title\n",
        "  Abstract = pd.DataFrame(list(abstracts.items()),columns = ['pmid','Title'])\n",
        "  return Abstract"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "71NrYJYsHtmw"
      },
      "outputs": [],
      "source": [
        "keyword = \"covid\"\n",
        "num_article = 300"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "s7n0BpPAH9Oq",
        "outputId": "b0726c4c-708c-4c88-a0de-16d701ce95e4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/requests/__init__.py:102: RequestsDependencyWarning: urllib3 (1.26.16) or chardet (5.1.0)/charset_normalizer (2.0.12) doesn't match a supported version!\n",
            "  warnings.warn(\"urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported \"\n",
            "2023-06-29 03:37:19 15cc8dae0b8c metapub.config[1968] WARNING NCBI_API_KEY was not set.\n"
          ]
        }
      ],
      "source": [
        "df_abs = get_pubmed_abs(keyword, num_article)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yzsdka4VIGdA"
      },
      "outputs": [],
      "source": [
        "df_abs.dropna(inplace = True)\n",
        "df_abs.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UBBGMl27IURm"
      },
      "outputs": [],
      "source": [
        "df_abs[\"Abstract\"] = df_abs[\"Abstract\"]\\\n",
        ".apply(lambda x: x.replace(\"INTRODUCTION:\",\"\"))\\\n",
        ".apply(lambda x: x.replace(\"IMPORTANCE:\",\"\"))\\\n",
        ".apply(lambda x: x.replace(\"BACKGROUND:\",\"\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GqQDmqmUIhis"
      },
      "outputs": [],
      "source": [
        "df_abs.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kK3IS-tqyaNB"
      },
      "source": [
        "**Clean text remove puctuations**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aIm9dy6KL96S"
      },
      "outputs": [],
      "source": [
        "def cleanup_text(text):\n",
        "    import re\n",
        "    # remove punctuation\n",
        "    text = re.sub('[^a-zA-Z0-9]', ' ', text)\n",
        "    # remove multiple spaces\n",
        "    text = re.sub(r' +', ' ', text)\n",
        "    # remove newline\n",
        "    text = re.sub(r'\\n', ' ', text)\n",
        "    return text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "722-FcXwyntx"
      },
      "source": [
        "**Save text data into the csv file **"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aDgZAF1bMbvm"
      },
      "outputs": [],
      "source": [
        "df_abs[\"Abstract\"] = df_abs[\"Abstract\"].apply(lambda x: cleanup_text(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XIMOLAWyKfKH"
      },
      "outputs": [],
      "source": [
        "df_abs.to_csv(os.path.join(data_dir, \"pubmed_abs.csv\"), index = False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}